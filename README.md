# STR-Net

*A Swin Transformer-based Reconstruction Framework for Near-Field Millimeter-Wave Radar Imaging*

---

## ğŸ›°ï¸ Overview

**STR-Net** is a deep learning framework for **near-field millimeter-wave radar imaging** based on a 3D Swin Transformer architecture.
It refines coarse reflectivity maps obtained from physics-based adjoint operations and reconstructs high-resolution images with improved structural fidelity.
The method is applicable to **security screening, through-wall sensing, and medical diagnostics**, where accurate and efficient 3D imaging is required.

---

## ğŸŒŸ Key Features & Contributions

* **3D SwinUNet Architecture** â€“ Combines Swin Transformer and UNet-style encoderâ€“decoder for efficient multi-scale feature modeling.
* **Multi-Scale Feature Fusion (MSF) Block** â€“ Adaptively integrates features at different resolutions.
* **Multi-Dimensional Spatial Attention (MDSA) Module** â€“ Captures spatial dependencies along depth, height, and width dimensions.
* **Hybrid Loss Function (MSE + L2)** â€“ Balances reconstruction accuracy and smoothness while accelerating convergence.

---

## âš™ï¸ Installation

We recommend using a virtual environment.

```bash
git clone https://github.com/Meicarl/STR-Net.git
cd STR-Net
pip install -r requirements.txt
```

> ğŸ’¡ For GPU users:
> Please install the matching PyTorch and CUDA versions from the [official PyTorch website](https://pytorch.org/) before running the above command.

---

## ğŸš€ Quick Start

Example of loading the pretrained model in Python:

```python
from strnet.models.STR_Net import STR_Net
import torch

model = STR_Net()
model.load_state_dict(torch.load('model/best.pt', map_location='cpu'))
model.eval()
```

Or run the demo notebook:

```bash
jupyter notebook r3d_show.ipynb
```

The notebook includes:

* Data loading and preprocessing
* Model loading and inference
* Visualization of reconstructed radar images

---

## ğŸ§© Data & Model

* Example data (`.npy`) is included in the `data/` folder.
* Pretrained weights can be downloaded from the following link and placed in the `model/` directory:
  ğŸ”— [Quark Cloud Link](https://pan.quark.cn/s/0e3248f46240)

> For custom datasets, refer to `strnet/datasets/` for data loading templates.

---

## ğŸ““ Demo Example

After running the notebook, you will see a visualization similar to:

| Initial Physics-Based Reconstruction |     STR-Net Enhanced Result    |
| :----------------------------------: | :----------------------------: |
|    ![](docs/adj3d.png)    |    ![](docs/strnet3d.png)    |
|    ![](docs/adj2d.png)    |    ![](docs/strnet2d.png)    |



---

## ğŸ“ Project Structure

```
STR-Net/
â”œâ”€â”€ strnet/                 # Core package
â”‚   â”œâ”€â”€ blocks/             # Basic convolution and UNet modules
â”‚   â”œâ”€â”€ models/             # 3D Swin Transformer model implementations
â”‚   â”œâ”€â”€ datasets/           # Dataset loading and processing tools
â”‚   â”œâ”€â”€ losses/             # Loss functions
â”‚   â””â”€â”€ utils/              # Visualization and utility functions
â”œâ”€â”€ data/                   # Example data
â”œâ”€â”€ model/                  # Pretrained model weights
â”œâ”€â”€ r3d_show.ipynb          # Demonstration notebook
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE
```

---

## ğŸ“œ License

This project is released under the **MIT License**.
See the [LICENSE](./LICENSE) file for details.

---

## ğŸ“š Citation

If you use this project or find it helpful in your research, please cite it as:

```
@article{STR-Net2025,
  title   = {STR-Net: A Swin Transformer-Based Reconstruction Framework for Near-Field Millimeter-Wave Radar Imaging},
  author  = {Jin, Shaohui and Zhao, Pengfei and Wei, Xinnian and Jiang, Xiaoheng and Zhang, Wenjie and Liu, Hao},
  journal = {Sensors},
  year    = {2025}
}
```